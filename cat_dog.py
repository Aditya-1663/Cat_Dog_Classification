# -*- coding: utf-8 -*-
"""cat_dog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CU027rCpq18gu8-elUhWW0xftmuk225h
"""

# !mydir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !cp /content/kaggle.json
# !cp --help

import json

# Upload your Kaggle API credentials JSON file and specify the path
kaggle_json_path = '/content/kaggle.json'

# Load the JSON file
with open(kaggle_json_path, 'r') as file:
    kaggle_json = json.load(file)

# Set Kaggle API credentials
import os

os.environ['KAGGLE_USERNAME'] = kaggle_json['username']
os.environ['KAGGLE_KEY'] = kaggle_json['key']

!kaggle datasets download -d salader/dogs-vs-cats

import zipfile
zip_ref=zipfile.ZipFile('/content/dogs-vs-cats.zip','r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout

#generators
train_data=keras.utils.image_dataset_from_directory(
    directory='/content/train',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)

)
validation_data=keras.utils.image_dataset_from_directory(
    directory='/content/test',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)

)

def process(image,label):
  image=tf.cast(image/255.,tf.float32)
  return image,label
train_data=train_data.map(process)
validation_data=validation_data.map(process)

# crete CNN model
model =Sequential()
model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))
model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0,1))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0,1))
model.add(Dense(1,activation='sigmoid'))

# model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
train_data
history=model.fit(train_data,epochs=10,validation_data=validation_data)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='green',label='test')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['loss'],color='red',label='loss')
plt.plot(history.history['val_loss'],color='green',label='val_loss')
plt.legend()
plt.show()

import cv2
test_img=cv2.imread('/content/cat.jpeg')
plt.imshow(test_img)

test_img.shape

test_img=cv2.resize(test_img,(256,256))

test_img.shape

test_input=test_img.reshape((1,256,256,3))

import pandas as pd
import numpy as np
h=np.array(test_input)

# df=pd.DataFrame(h,colum)

g=model.predict(test_input)

int(g[0][0])